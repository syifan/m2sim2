name: CI Health Monitor

on:
  schedule:
    - cron: '0 */6 * * *'  # Every 6 hours
  workflow_dispatch:

jobs:
  ci-health-check:
    name: CI Health Assessment
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Analyze recent CI runs
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Get recent workflow runs for all critical workflows
          echo "Analyzing CI health for the last 24 hours..."

          python3 - <<'PYEOF'
          import json
          import subprocess
          import sys
          from datetime import datetime, timedelta

          def get_recent_runs(workflow_name, hours=24):
              """Get recent runs for a specific workflow"""
              cmd = ['gh', 'run', 'list', '--workflow', workflow_name, '--json', 'status,conclusion,createdAt,id,name', '--limit', '20']
              result = subprocess.run(cmd, capture_output=True, text=True)
              if result.returncode != 0:
                  print(f"Warning: Could not fetch runs for {workflow_name}")
                  return []

              runs = json.loads(result.stdout)
              cutoff = datetime.now() - timedelta(hours=hours)

              recent_runs = []
              for run in runs:
                  created_at = datetime.fromisoformat(run['createdAt'].replace('Z', '+00:00'))
                  if created_at > cutoff:
                      recent_runs.append(run)

              return recent_runs

          # Critical workflows to monitor
          workflows = [
              'ci.yml',
              'h5-accuracy-report.yml',
              'polybench-sim.yml',
              'cpi-comparison.yml',
              'matmul-calibration.yml'
          ]

          health_report = {
              "timestamp": datetime.now().isoformat(),
              "period_hours": 24,
              "workflows": {},
              "overall_health": "unknown",
              "alerts": []
          }

          total_runs = 0
          failed_runs = 0
          timeout_failures = 0

          for workflow in workflows:
              runs = get_recent_runs(workflow)
              if not runs:
                  health_report["workflows"][workflow] = {
                      "runs": 0,
                      "success_rate": 0.0,
                      "status": "no_data"
                  }
                  continue

              completed_runs = [r for r in runs if r['status'] == 'completed']
              successful_runs = [r for r in completed_runs if r['conclusion'] == 'success']
              failed_runs_count = len([r for r in completed_runs if r['conclusion'] in ['failure', 'cancelled', 'timed_out']])

              success_rate = len(successful_runs) / len(completed_runs) if completed_runs else 0.0

              health_report["workflows"][workflow] = {
                  "runs": len(runs),
                  "completed": len(completed_runs),
                  "successful": len(successful_runs),
                  "failed": failed_runs_count,
                  "success_rate": success_rate,
                  "status": "healthy" if success_rate >= 0.8 else "degraded" if success_rate >= 0.5 else "critical"
              }

              total_runs += len(completed_runs)
              failed_runs += failed_runs_count

              # Check for timeout patterns
              timeout_runs = [r for r in completed_runs if r['conclusion'] == 'timed_out']
              if timeout_runs:
                  timeout_failures += len(timeout_runs)
                  health_report["alerts"].append(f"{workflow}: {len(timeout_runs)} timeout failures detected")

              # Check for low success rates
              if success_rate < 0.7:
                  health_report["alerts"].append(f"{workflow}: Low success rate ({success_rate:.1%})")

          # Calculate overall health
          overall_success_rate = (total_runs - failed_runs) / total_runs if total_runs > 0 else 0.0

          if overall_success_rate >= 0.9:
              health_report["overall_health"] = "healthy"
          elif overall_success_rate >= 0.7:
              health_report["overall_health"] = "degraded"
          else:
              health_report["overall_health"] = "critical"

          health_report["summary"] = {
              "total_runs": total_runs,
              "failed_runs": failed_runs,
              "timeout_failures": timeout_failures,
              "overall_success_rate": overall_success_rate
          }

          # Write health report
          with open("ci_health_report.json", "w") as f:
              json.dump(health_report, f, indent=2)

          print("=== CI Health Report ===")
          print(json.dumps(health_report, indent=2))

          # Exit with error code if critical issues detected
          if health_report["overall_health"] == "critical" or timeout_failures > 3:
              print(f"\n‚ùå CRITICAL: CI health is {health_report['overall_health']}")
              if timeout_failures > 3:
                  print(f"‚ùå CRITICAL: {timeout_failures} timeout failures detected")
              sys.exit(1)
          elif health_report["overall_health"] == "degraded":
              print(f"\n‚ö†Ô∏è WARNING: CI health is degraded")
          else:
              print(f"\n‚úÖ CI health is good")
          PYEOF

      - name: Check for silent failures
        run: |
          echo "Checking for silent failure patterns..."

          # Check if any critical workflows haven't run recently when they should have
          python3 - <<'PYEOF'
          import json
          import subprocess
          from datetime import datetime, timedelta

          def check_workflow_freshness():
              """Check if critical workflows have run recently enough"""
              alerts = []

              # Workflows that should run on every push to main
              critical_workflows = ['ci.yml', 'h5-accuracy-report.yml']

              # Get recent commits to main
              result = subprocess.run(['git', 'log', '--since=1 day ago', '--oneline', 'main'],
                                    capture_output=True, text=True)
              recent_commits = len(result.stdout.strip().split('\n')) if result.stdout.strip() else 0

              if recent_commits > 0:
                  for workflow in critical_workflows:
                      cmd = ['gh', 'run', 'list', '--workflow', workflow, '--json', 'createdAt', '--limit', '5']
                      result = subprocess.run(cmd, capture_output=True, text=True)

                      if result.returncode == 0:
                          runs = json.loads(result.stdout)
                          if runs:
                              latest_run = datetime.fromisoformat(runs[0]['createdAt'].replace('Z', '+00:00'))
                              hours_since = (datetime.now() - latest_run).total_seconds() / 3600

                              if hours_since > 12:  # No runs in 12+ hours despite commits
                                  alerts.append(f"{workflow}: No runs in {hours_since:.1f} hours despite recent commits")
                          else:
                              alerts.append(f"{workflow}: No recent runs found")

              return alerts

          silent_failure_alerts = check_workflow_freshness()

          if silent_failure_alerts:
              print("üîç SILENT FAILURE DETECTION:")
              for alert in silent_failure_alerts:
                  print(f"  ‚ùå {alert}")
          else:
              print("‚úÖ No silent failures detected")

          # Append to health report
          try:
              with open("ci_health_report.json", "r") as f:
                  health_report = json.load(f)

              health_report["silent_failures"] = silent_failure_alerts

              with open("ci_health_report.json", "w") as f:
                  json.dump(health_report, f, indent=2)
          except:
              pass
          PYEOF

      - name: Generate health summary
        if: always()
        run: |
          echo "## CI Health Monitor Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ -f ci_health_report.json ]; then
            python3 -c "
          import json
          try:
              d = json.load(open('ci_health_report.json'))
              print(f\"**Overall Health:** {d['overall_health'].title()}\")
              print(f\"**Success Rate:** {d['summary']['overall_success_rate']:.1%} ({d['summary']['failed_runs']} failures out of {d['summary']['total_runs']} runs)\")
              print(f\"**Timeout Failures:** {d['summary']['timeout_failures']}\")
              print()

              print('### Workflow Status')
              for workflow, status in d['workflows'].items():
                  icon = '‚úÖ' if status['status'] == 'healthy' else '‚ö†Ô∏è' if status['status'] == 'degraded' else '‚ùå'
                  print(f'{icon} **{workflow}**: {status[\"success_rate\"]:.1%} success rate ({status[\"successful\"]}/{status[\"completed\"]} runs)')

              if d.get('alerts'):
                  print()
                  print('### Alerts')
                  for alert in d['alerts']:
                      print(f'‚ö†Ô∏è {alert}')

              if d.get('silent_failures'):
                  print()
                  print('### Silent Failure Detection')
                  for failure in d['silent_failures']:
                      print(f'üîç {failure}')
          except Exception as e:
              print(f'Error processing health report: {e}')
          " >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ùå Health report generation failed." >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload health report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ci-health-report
          path: ci_health_report.json
          retention-days: 30

      - name: Comment on infrastructure issues if critical
        if: always()
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          if [ -f ci_health_report.json ]; then
            HEALTH_STATUS=$(python3 -c "import json; d=json.load(open('ci_health_report.json')); print(d['overall_health'])")
            TIMEOUT_FAILURES=$(python3 -c "import json; d=json.load(open('ci_health_report.json')); print(d['summary']['timeout_failures'])")

            if [ "$HEALTH_STATUS" = "critical" ] || [ "$TIMEOUT_FAILURES" -gt 3 ]; then
              echo "Critical CI health detected, would create infrastructure issue if not already exists..."
              # Note: In production, this would create an issue or comment on existing infrastructure issues
            fi
          fi