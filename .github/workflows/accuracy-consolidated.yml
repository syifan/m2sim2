name: Accuracy - Consolidated

on:
  workflow_dispatch:
  workflow_run:
    workflows:
      - "Accuracy - Microbenchmarks"
      - "Accuracy - PolyBench"
    types:
      - completed

jobs:
  consolidate:
    name: Consolidate All Accuracy Results
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download latest accuracy-microbench artifact
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          mkdir -p artifacts/microbench
          ARTIFACT_URL=$(gh api "repos/${{ github.repository }}/actions/artifacts?name=accuracy-microbench" \
            --jq '[.artifacts[] | select(.expired == false)] | sort_by(.created_at) | last | .archive_download_url')
          if [ -z "$ARTIFACT_URL" ] || [ "$ARTIFACT_URL" = "null" ]; then
            echo "::warning::No accuracy-microbench artifact found"
          else
            gh api "$ARTIFACT_URL" > /tmp/microbench.zip
            unzip -o /tmp/microbench.zip -d artifacts/microbench
          fi

      - name: Download latest polybench-consolidated artifact
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          mkdir -p artifacts/polybench
          ARTIFACT_URL=$(gh api "repos/${{ github.repository }}/actions/artifacts?name=polybench-consolidated" \
            --jq '[.artifacts[] | select(.expired == false)] | sort_by(.created_at) | last | .archive_download_url')
          if [ -z "$ARTIFACT_URL" ] || [ "$ARTIFACT_URL" = "null" ]; then
            echo "::warning::No polybench-consolidated artifact found"
          else
            gh api "$ARTIFACT_URL" > /tmp/polybench.zip
            unzip -o /tmp/polybench.zip -d artifacts/polybench
          fi

      - name: Download latest embench-accuracy artifact
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          mkdir -p artifacts/embench
          ARTIFACT_URL=$(gh api "repos/${{ github.repository }}/actions/artifacts?name=embench-accuracy" \
            --jq '[.artifacts[] | select(.expired == false)] | sort_by(.created_at) | last | .archive_download_url')
          if [ -z "$ARTIFACT_URL" ] || [ "$ARTIFACT_URL" = "null" ]; then
            echo "::warning::No embench-accuracy artifact found"
          else
            gh api "$ARTIFACT_URL" > /tmp/embench.zip
            unzip -o /tmp/embench.zip -d artifacts/embench
          fi

      - name: Consolidate results and compute errors
        run: |
          python3 - <<'PYEOF'
          import json, os

          # Hardware reference CPI from calibration_results.json
          # hw_cpi = instruction_latency_ns * 3.5 GHz
          hw_cpi = {
              "arithmetic": 0.296,
              "dependency": 1.088,
              "branch": 1.303,
              "memorystrided": 2.648,
              "loadheavy": 0.429,
              "storeheavy": 0.612,
              "branchheavy": 0.714,
              "vectorsum": 0.402,
              "vectoradd": 0.329,
              "reductiontree": 0.480,
              "strideindirect": 0.528,
          }

          consolidated = {
              "microbench": {"available": False, "results": {}},
              "polybench": {"available": False, "results": {}},
              "embench": {"available": False, "results": {}},
              "error_metrics": {},
          }

          # Load microbench results
          micro_path = "artifacts/microbench/microbench_results.json"
          if os.path.exists(micro_path):
              with open(micro_path) as f:
                  data = json.load(f)
              consolidated["microbench"] = {
                  "available": True,
                  "benchmarks_run": data.get("benchmarks_run", 0),
                  "results": data.get("results", {}),
              }

          # Load polybench results
          poly_path = "artifacts/polybench/polybench_results.json"
          if os.path.exists(poly_path):
              with open(poly_path) as f:
                  data = json.load(f)
              consolidated["polybench"] = {
                  "available": True,
                  "benchmarks_run": data.get("benchmarks_run", 0),
                  "results": data.get("results", {}),
              }

          # Load embench results
          embench_path = "artifacts/embench/embench_results.json"
          if os.path.exists(embench_path):
              with open(embench_path) as f:
                  data = json.load(f)
              consolidated["embench"] = {
                  "available": True,
                  "benchmarks_run": data.get("benchmarks_run", 0),
                  "results": data.get("results", {}),
              }

          # Compute error metrics for microbenchmarks vs hardware reference
          errors = {}
          micro_results = consolidated["microbench"].get("results", {})
          for bench_name, ref_cpi in hw_cpi.items():
              if bench_name in micro_results:
                  sim_cpi = micro_results[bench_name]["cpi"]
                  error = abs(sim_cpi - ref_cpi) / min(sim_cpi, ref_cpi)
                  errors[bench_name] = {
                      "sim_cpi": sim_cpi,
                      "hw_cpi": ref_cpi,
                      "error": round(error, 4),
                  }
              else:
                  errors[bench_name] = {
                      "sim_cpi": None,
                      "hw_cpi": ref_cpi,
                      "error": None,
                      "note": "infeasible - no simulation result",
                  }
          consolidated["error_metrics"] = errors

          with open("accuracy_consolidated.json", "w") as f:
              json.dump(consolidated, f, indent=2)

          print(json.dumps(consolidated, indent=2))
          PYEOF

      - name: Generate h5_accuracy_results.json
        run: |
          python3 - <<'PYEOF'
          import json, os

          if not os.path.exists("accuracy_consolidated.json"):
              print("No consolidated results, skipping h5 generation")
              exit(0)

          with open("accuracy_consolidated.json") as f:
              data = json.load(f)

          errors = data.get("error_metrics", {})

          # Collect all benchmarks with valid error measurements
          valid_errors = {}
          for name, m in errors.items():
              if m.get("error") is not None:
                  valid_errors[name] = m["error"]

          # Count total benchmarks across all suites
          total_benchmarks = 0
          for suite in ["microbench", "polybench", "embench"]:
              suite_data = data.get(suite, {})
              if suite_data.get("available") and suite_data.get("results"):
                  total_benchmarks += len(suite_data["results"])

          avg_error = sum(valid_errors.values()) / len(valid_errors) if valid_errors else None

          h5 = {
              "total_benchmarks_run": total_benchmarks,
              "benchmarks_with_error_data": len(valid_errors),
              "average_error": round(avg_error, 4) if avg_error is not None else None,
              "max_error": round(max(valid_errors.values()), 4) if valid_errors else None,
              "min_error": round(min(valid_errors.values()), 4) if valid_errors else None,
              "max_error_benchmark": max(valid_errors, key=valid_errors.get) if valid_errors else None,
              "min_error_benchmark": min(valid_errors, key=valid_errors.get) if valid_errors else None,
              "per_benchmark_errors": {k: round(v, 4) for k, v in sorted(valid_errors.items())},
              "suites": {
                  "microbench": {"available": data["microbench"].get("available", False),
                                 "count": len(data["microbench"].get("results", {}))},
                  "polybench": {"available": data["polybench"].get("available", False),
                                "count": len(data["polybench"].get("results", {}))},
                  "embench": {"available": data["embench"].get("available", False),
                              "count": len(data["embench"].get("results", {}))},
              },
          }

          with open("h5_accuracy_results.json", "w") as f:
              json.dump(h5, f, indent=2)

          print("=== h5_accuracy_results.json ===")
          print(json.dumps(h5, indent=2))

          if avg_error is not None:
              print(f"\nOverall average error: {avg_error:.2%} across {len(valid_errors)} benchmarks")
              print(f"Total benchmarks run: {total_benchmarks}")
          PYEOF

      - name: Post summary
        if: always()
        run: |
          echo "## Consolidated Accuracy Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ ! -f accuracy_consolidated.json ]; then
            echo "No consolidated results generated." >> $GITHUB_STEP_SUMMARY
            exit 0
          fi
          python3 - <<'PYEOF' >> $GITHUB_STEP_SUMMARY
          import json, os

          d = json.load(open("accuracy_consolidated.json"))

          # Microbench summary
          micro = d["microbench"]
          print(f'### Microbenchmarks (available: {micro["available"]})')
          if micro["available"] and micro.get("results"):
              print(f'Benchmarks run: {micro["benchmarks_run"]}/11')
              print()
              print("| Benchmark | Sim CPI | HW CPI | Error |")
              print("|-----------|---------|--------|-------|")
              for name, m in sorted(d["error_metrics"].items()):
                  sim = f'{m["sim_cpi"]:.3f}' if m["sim_cpi"] is not None else "N/A"
                  err = f'{m["error"]:.1%}' if m["error"] is not None else "infeasible"
                  print(f'| {name} | {sim} | {m["hw_cpi"]:.3f} | {err} |')
          print()

          # Polybench summary
          poly = d["polybench"]
          print(f'### PolyBench (available: {poly["available"]})')
          if poly["available"] and poly.get("results"):
              print(f'Benchmarks run: {poly["benchmarks_run"]}/7')
              print()
              print("| Benchmark | CPI |")
              print("|-----------|-----|")
              for name, r in sorted(poly["results"].items()):
                  print(f'| {name} | {r["cpi"]:.3f} |')
          print()

          # EmBench summary
          emb = d["embench"]
          print(f'### EmBench (available: {emb["available"]})')
          if emb["available"] and emb.get("results"):
              print(f'Benchmarks run: {emb["benchmarks_run"]}/7')
              print()
              print("| Benchmark | CPI |")
              print("|-----------|-----|")
              for name, r in sorted(emb["results"].items()):
                  print(f'| {name} | {r["cpi"]:.3f} |')

          # H5 overall summary
          if os.path.exists("h5_accuracy_results.json"):
              h5 = json.load(open("h5_accuracy_results.json"))
              print()
              print("### Overall H5 Summary")
              if h5.get("average_error") is not None:
                  print(f'- **Average error:** {h5["average_error"]:.2%} ({h5["benchmarks_with_error_data"]} benchmarks with error data)')
                  print(f'- **Total benchmarks run:** {h5["total_benchmarks_run"]}')
                  print(f'- **Max error:** {h5["max_error"]:.2%} ({h5["max_error_benchmark"]})')
                  print(f'- **Min error:** {h5["min_error"]:.2%} ({h5["min_error_benchmark"]})')
              else:
                  print("No error data available yet.")
          PYEOF

      - name: Upload consolidated artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: accuracy-consolidated
          path: |
            accuracy_consolidated.json
            h5_accuracy_results.json
          retention-days: 90
