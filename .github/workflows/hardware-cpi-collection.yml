name: Hardware CPI Collection - PolyBench

on:
  workflow_dispatch:
  push:
    paths:
      - 'benchmarks/polybench/**'

jobs:
  collect-cpi:
    name: Collect Hardware CPI on Apple M2
    runs-on: macos-14
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Build and measure all benchmarks
        run: |
          python3 - <<'PYEOF'
          import subprocess, json, re, statistics, os

          # 2mm and 3mm use MINI_DATASET (16x16) because SMALL exceeds CI timeout.
          # All other benchmarks use SMALL_DATASET.
          BENCHMARKS = {
              "atax":      {"dir": "atax",      "instructions": 130927,  "iters": 1000, "dataset": "SMALL"},
              "bicg":      {"dir": "bicg",      "instructions": 112372,  "iters": 1000, "dataset": "SMALL"},
              "gemm":      {"dir": "gemm",      "instructions": 2516282, "iters": 200,  "dataset": "SMALL"},
              "mvt":       {"dir": "mvt",       "instructions": 124920,  "iters": 1000, "dataset": "SMALL"},
              "jacobi-1d": {"dir": "jacobi-1d", "instructions": 49248,   "iters": 2000, "dataset": "SMALL"},
              "2mm":       {"dir": "2mm",       "instructions": 69563,   "iters": 2000, "dataset": "MINI"},
              "3mm":       {"dir": "3mm",       "instructions": 105410,  "iters": 1000, "dataset": "MINI"},
          }

          FREQUENCY_GHZ = 3.5
          ROUNDS = 5
          POLY_DIR = "benchmarks/polybench"
          INCLUDE_DIR = os.path.join(POLY_DIR, "common")

          CC = "cc"
          BASE_CFLAGS = [
              "-O2", "-mcpu=apple-m2",
              "-fno-vectorize", "-fno-slp-vectorize",
              "-DPOLYBENCH_USE_RESTRICT",
              f"-I{INCLUDE_DIR}",
          ]

          WRAPPER_TEMPLATE = """\
          #define main _original_main
          #include "{src_path}"
          #undef main

          #include <time.h>
          #include <stdio.h>

          int main(void) {{
              struct timespec start, end;
              clock_gettime(CLOCK_MONOTONIC, &start);
              for (int iter = 0; iter < {iters}; iter++) {{
                  _original_main();
              }}
              clock_gettime(CLOCK_MONOTONIC, &end);
              double elapsed = (end.tv_sec - start.tv_sec)
                             + (end.tv_nsec - start.tv_nsec) / 1e9;
              printf("TIMING: %.9f %d\\n", elapsed, {iters});
              return 0;
          }}
          """

          results = {}

          for name, info in BENCHMARKS.items():
              src_rel = os.path.join(POLY_DIR, info["dir"], f"{info['dir']}.c")
              wrapper_file = f"{name}_timed.c"
              binary = f"{name}_timed"
              dataset = info["dataset"]

              # Per-benchmark CFLAGS with appropriate dataset
              cflags = BASE_CFLAGS + [f"-D{dataset}_DATASET"]

              # Generate wrapper C source
              wrapper_src = WRAPPER_TEMPLATE.format(
                  src_path=src_rel,
                  iters=info["iters"],
              )
              with open(wrapper_file, "w") as f:
                  f.write(wrapper_src)

              # Build wrapper
              cmd = [CC] + cflags + [wrapper_file, "-o", binary]
              print(f"Building {name} ({dataset}_DATASET): {' '.join(cmd)}")
              subprocess.run(cmd, check=True)

              # Measure: run binary ROUNDS times, parse TIMING line, take median
              round_times = []
              for r in range(ROUNDS):
                  result = subprocess.run(
                      [f"./{binary}"], capture_output=True, text=True, check=True,
                  )
                  m = re.search(r"TIMING:\s+([\d.]+)\s+(\d+)", result.stdout)
                  if not m:
                      raise RuntimeError(f"{name} round {r+1}: no TIMING line in output")
                  elapsed = float(m.group(1))
                  iters = int(m.group(2))
                  time_per_run = elapsed / iters
                  round_times.append(time_per_run)
                  print(f"  Round {r+1}/{ROUNDS}: {elapsed:.6f}s / {iters} iters = {time_per_run*1e6:.4f}us per run")

              median_time = statistics.median(round_times)
              cycles = median_time * FREQUENCY_GHZ * 1e9
              cpi = cycles / info["instructions"]

              results[name] = {
                  "dataset": dataset,
                  "instructions": info["instructions"],
                  "avg_time_sec": round(median_time, 12),
                  "estimated_cycles": round(cycles, 1),
                  "cpi": round(cpi, 4),
                  "all_round_times_sec": [round(t, 12) for t in round_times],
              }
              print(f"  -> median_time={median_time*1e9:.2f}ns, cycles={cycles:.1f}, CPI={cpi:.4f}")

              # Clean up
              os.remove(wrapper_file)
              os.remove(binary)

          output = {
              "dataset": "SMALL (2mm/3mm: MINI)",
              "runner": "macos-14",
              "frequency_ghz": FREQUENCY_GHZ,
              "program_iterations": {n: info["iters"] for n, info in BENCHMARKS.items()},
              "rounds": ROUNDS,
              "benchmarks": results,
          }

          with open("hardware-cpi-polybench.json", "w") as f:
              json.dump(output, f, indent=2)

          print("\n=== Final Results ===")
          print(json.dumps(output, indent=2))
          PYEOF

      - name: Post summary
        if: always()
        run: |
          echo "## Hardware CPI Collection â€” PolyBench on Apple M2" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ ! -f hardware-cpi-polybench.json ]; then
            echo "No results generated." >> $GITHUB_STEP_SUMMARY
            exit 0
          fi
          python3 - <<'PYEOF' >> $GITHUB_STEP_SUMMARY
          import json

          data = json.load(open("hardware-cpi-polybench.json"))
          print(f"- **Dataset:** {data['dataset']}")
          print(f"- **Runner:** {data['runner']}")
          print(f"- **Frequency:** {data['frequency_ghz']} GHz")
          print(f"- **Rounds:** {data['rounds']}")
          if "program_iterations" in data:
              iters = data["program_iterations"]
              print(f"- **Program iterations:** {', '.join(f'{k}={v}' for k,v in sorted(iters.items()))}")
          elif "kernel_iterations" in data:
              iters = data["kernel_iterations"]
              print(f"- **Kernel iterations:** {', '.join(f'{k}={v}' for k,v in sorted(iters.items()))}")
          print()
          print("| Benchmark | Dataset | Instructions | Avg Time (us) | Est. Cycles | CPI |")
          print("|-----------|---------|-------------|---------------|-------------|-----|")
          for name, r in sorted(data["benchmarks"].items()):
              t_us = r["avg_time_sec"] * 1e6
              ds = r.get("dataset", "SMALL")
              print(f"| {name} | {ds} | {r['instructions']} | {t_us:.2f} | {r['estimated_cycles']:.1f} | {r['cpi']:.4f} |")
          PYEOF

      - name: Upload artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: hardware-cpi-polybench
          path: hardware-cpi-polybench.json
          retention-days: 90
